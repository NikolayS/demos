{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install keras\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import dotscience as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex_binary'] = np.where(df['Sex'] == \"female\", 1, 0)\n",
    "df.drop(columns='Sex', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Embarked_ternary to 1 for C, 2 for Q, 3 for S\n",
    "df['Embarked_ternary'] = np.where(df[\"Embarked\"] == \"C\", 1, \n",
    "         (np.where(df[\"Embarked\"] == \"Q\", 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nan = len(df['Cabin']) - df['Cabin'].count()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so most of the Cabin values are NaN, so we can probably drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Cabin', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly more likely to survive if younger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Survived']).Age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher average fare amongst survivors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.groupby(['Survived']).Fare.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does survival vary with embarkation point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number embarked at Cherbourg\", len(df.loc[df['Embarked_ternary'] == 1]))\n",
    "print(\"average survival status\", df.loc[df['Embarked_ternary'] == 1].Survived.mean())\n",
    "print(\"\\n\")\n",
    "print(\"number embarked at Queenstown\", len(df.loc[df['Embarked_ternary'] == 2]))\n",
    "print(\"average survival status\", df.loc[df['Embarked_ternary'] == 2].Survived.mean())\n",
    "print(\"\\n\")\n",
    "print(\"number embarked at Southampton\", len(df.loc[df['Embarked_ternary'] == 3]))\n",
    "print(\"average survival status\", df.loc[df['Embarked_ternary'] == 3].Survived.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so there is some evidence that embarking at Cherbourg is correlated with survival. So let's turn embarkation_ternary into a binary condition: emarbarked_at_cherbourg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked_at_cherbourg'] = np.where(df['Embarked_ternary'] == 1, 1, 0)\n",
    "df.drop(columns=\"Embarked_ternary\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do the name lengths vary? And are they correlated with survival?\n",
    "\n",
    "names_lens = [(name[1], len(name[1])) for name in df[\"Name\"].iteritems()]\n",
    "name_lens = [name_len[1] for name_len in names_lens]\n",
    "plt.hist(name_lens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an int value for name length\n",
    "df['Name_len'] = [len(name[1]) for name in df[\"Name\"].iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "woah, having a long name is almost as highly correlated with survival as passanger class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: engineer ticket class\n",
    "# for now, we'll just drop it\n",
    "\n",
    "df.drop(columns=['PassengerId', 'Embarked', 'Name', 'Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some null ages. Let's see how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df.Age.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naively fill nulls for now. Better to predict missing ages on basis of available data.\n",
    "\n",
    "# test data also has nulls, so fill those in in same way.\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Survived/not Survived as  categorical value, to make compatible  with network and to use categorical_crossentropy as loss metric.\n",
    "(train_passengers, train_labels) = (df.drop('Survived', axis=1), keras.utils.to_categorical(df['Survived'], num_classes=None, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(train_passengers)\n",
    "scaler.transform(train_passengers, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_passengers is df\n",
    "train_passengers[train_passengers.columns] = scaler.fit_transform(train_passengers[train_passengers.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function with preceding data-wrangling steps, so that we can perform the same operations on the test set\n",
    "def wrangle(df):\n",
    "    \"\"\"\n",
    "    takes a df with same format as training set.\n",
    "    returns df in same format as modified training set\n",
    "    \"\"\"\n",
    "    df['Sex_binary'] = np.where(df['Sex'] == \"female\", 1, 0)\n",
    "    df.drop(columns='Sex', inplace=True)\n",
    "    df['Embarked_ternary'] = np.where(df[\"Embarked\"] == \"C\", 1, \n",
    "         (np.where(df[\"Embarked\"] == \"Q\", 2, 3)))\n",
    "    df.drop(columns='Cabin', inplace=True)\n",
    "    df['Embarked_at_cherbourg'] = np.where(df['Embarked_ternary'] == 1, 1, 0)\n",
    "    df.drop(columns=\"Embarked_ternary\", inplace=True)\n",
    "    names_lens = [(name[1], len(name[1])) for name in df[\"Name\"].iteritems()]\n",
    "    name_lens = [name_len[1] for name_len in names_lens]\n",
    "    df['Name_len'] = [len(name[1]) for name in df[\"Name\"].iteritems()]    \n",
    "    df.drop(columns=['PassengerId', 'Embarked', 'Name', 'Ticket'], inplace=True)\n",
    "    \n",
    "    # naively fill in nulls for now\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform test data\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test = wrangle(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_passengers = df_test\n",
    "test_passengers[test_passengers.columns] = scaler.fit_transform(test_passengers[test_passengers.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_passengers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import callbacks\n",
    "\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(input_dim=train_passengers.shape[1], units=128,\n",
    "                 kernel_initializer='normal', bias_initializer='zeros', kernel_regularizer=regularizers.l2(ds.parameter(\"reg_lambda\", 0.005))))\n",
    "\n",
    "network.add(Activation('relu'))\n",
    "\n",
    "for i in range(0, 5):\n",
    "    network.add(layers.Dense(units=128, kernel_initializer='normal',\n",
    "                     bias_initializer='zeros'))\n",
    "    network.add(Activation('relu'))\n",
    "    network.add(Dropout(.25))\n",
    "\n",
    "network.add(layers.Dense(units=2))\n",
    "network.add(Activation('softmax'))\n",
    "\n",
    "network.compile(loss='categorical_crossentropy', optimizer=ds.parameter(\"optimizer\", 'adam'), metrics=['accuracy'])\n",
    "\n",
    "# TODO: record loss history: https://keras.io/callbacks/#example-recording-loss-history\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"weights.h5\", monitor='categorical_crossentropy', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "network.fit(train_passengers, train_labels, epochs=ds.parameter(\"epochs\", 700), verbose=2, validation_split=0.1, callbacks=[callbacks.EarlyStopping(monitor='val_acc', patience=2)])\n",
    "\n",
    "# network.fit(train_passengers, train_labels, epochs=700, verbose=2, validation_split=0.1)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "acc = np.amax(network.history.history['acc'])\n",
    "\n",
    "ds.add_summary('acc%', acc)\n",
    "# ds.add_parameters(regulariser=\"none\", epocs=700, batch_size=\"default\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "print('Best validation acc of epoch:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With L2 regularisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(network.history.history['acc'])\n",
    "plt.plot(network.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(network.history.history['loss'])\n",
    "plt.plot(network.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(network.history.history['acc'])\n",
    "plt.plot(network.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(network.history.history['loss'])\n",
    "plt.plot(network.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(network.history.history['acc'])\n",
    "plt.plot(network.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(network.history.history['loss'])\n",
    "plt.plot(network.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like overfitting -- add more regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "# By default, this saves the model's weights in the TensorFlow checkpoint file format.\n",
    "network.save_weights(ds.output('weights'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = network.predict(test_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = []\n",
    "for result in results:\n",
    "    survived.append(result[1])\n",
    "\n",
    "\n",
    "plt.scatter(survived, range(len(survived)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need binary survival prediction, not a probability\n",
    "binary_results = network.predict_classes(test_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unwrangled version of test set with the passenger IDs\n",
    "df_test = pd.read_csv(\"test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for binary survival status\n",
    "df_test['Survived'] = binary_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.publish(\"did it work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out results\n",
    "df_test.drop(columns=['Pclass', 'Embarked', 'Name', 'Ticket', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Fare', 'Embarked'], inplace=True)\n",
    "df_test.to_csv(\"predictions.csv\", columns = ['PassengerId', 'Survived'], index=False)    \n",
    "df_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
