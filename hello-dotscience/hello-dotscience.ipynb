{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Dotscience!\n",
    "\n",
    "Dotscience is a _run tracker_ for data engineering and machine learning (ML).\n",
    "\n",
    "By tracking runs, Dotscience allows you to capture all of the inputs that go into creating ML models.\n",
    "\n",
    "Let's try a practical example! **Start by clicking on the \"Dotscience\" tab in the top left corner of the screen.**\n",
    "\n",
    "## Simplest possible \"hello world\"\n",
    "\n",
    "In this example, we create a single run and record with it a _run message_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotscience as ds\n",
    "ds.interactive()               # tell Dotscience we're running in Jupyter (as opposed to CLI/script mode)\n",
    "ds.start()                     # start a new run (also clears any metadata from any previous runs)\n",
    "ds.publish(\"did an empty run\") # publish the run (pushes it to the Dotscience Hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the cell above, and then click the \"â–º\" button in Jupyter, or press shift-enter.\n",
    "\n",
    "You'll notice that some metadata is printed after the cell. This metadata being written to the notebook file is the trigger for Dotscience recording a new run.\n",
    "\n",
    "You'll notice that within a second or two, in the Dotscience Status view, Dotscience has detected the run and captured a new run, which includes a snapshot of the files in the workspace as well as the metadata included in the run (which for now, is just the run message).\n",
    "\n",
    "You'll see the run captured in the Dotscience Runs status view. It's also pushed to the Dotscience Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture metrics\n",
    "\n",
    "Let's pretend we're doing training an ML model. ML models have parameters, like learning rates, and summary statistics, like accuracy. We can include these in the Dotscience metadata to record them for posterity and share them with our team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.start()                                 # start a new run\n",
    "ds.parameter(\"learning_rate\", 0.001)       # a pretend learning rate\n",
    "ds.summary(\"accuracy\", 0.99)               # a great accuracy score\n",
    "ds.publish(\"trained imaginary neural net\") # a meaningful run message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the run get captured in the Dotscience plugin and get pushed to the hub.\n",
    "\n",
    "Now click on the \"Activity\" and you should see the parameters and summary statistics shown in the table and in the chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest some data\n",
    "\n",
    "Now let's do something a bit more realistic. We're going to ingest some raw data, and then modify it (by combining two data sources into one), and then build a linear regression model to predict house prices.\n",
    "\n",
    "We can start by doing a data ingestion run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -qq -y wget\n",
    "ds.start()\n",
    "!wget -q -O data1.csv \\\n",
    "    https://github.com/dotmesh-io/dotscience-demo/blob/master/bay_area_zillow_agent1.csv?raw=true\n",
    "!wget -q -O data2.csv \\\n",
    "    https://github.com/dotmesh-io/dotscience-demo/blob/master/bay_area_zillow_agent2.csv?raw=true\n",
    "ds.output(\"data1.csv\")\n",
    "ds.output(\"data2.csv\")\n",
    "ds.publish(\"ingested zillow property data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now click \"Resources\", and click on one of the data files, and you'll see your first provenance graph - Dotscience is tracking that the given version of the data file came from a specific run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the datasets\n",
    "\n",
    "Now we'll combine the datasets and make another run which captures the act of doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds.start()\n",
    "inputs = [pd.read_csv(ds.input(\"data1.csv\")), pd.read_csv(ds.input(\"data2.csv\"))]\n",
    "df = pd.concat(f for f in inputs)\n",
    "df.to_csv(ds.output(\"combined.csv\"))\n",
    "ds.publish(\"combined data files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build a model!\n",
    "\n",
    "Now we'll put together a very simple linear regression, then we can track the provenance of the model data file as well as the accuracy statistics from testing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ds.start()\n",
    "features = ['finishedsqft']\n",
    "X = df[features]\n",
    "Y = df['lastsoldprice']\n",
    "\n",
    "ds.parameter('features',\", \".join(sorted(features)))\n",
    "\n",
    "df = pd.read_csv(ds.input('combined.csv'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "regressor_score = regressor.score(X_test, y_test)\n",
    "ds.summary('regressor_score', regressor_score)\n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "ds.summary('lin_rmse', lin_rmse)\n",
    "\n",
    "joblib.dump(regressor, ds.output('linear_regressor.pkl'))\n",
    "ds.publish(\"trained linear regression model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to inspect the provenance of the model file in the Resources section, and see the metrics of its performance in the Activity section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
